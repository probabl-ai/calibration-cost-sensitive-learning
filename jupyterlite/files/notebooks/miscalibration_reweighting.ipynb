{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "73eb600f",
   "metadata": {},
   "source": [
    "\n",
    "# Miscalibration caused by data points reweighting\n",
    "\n",
    "Another cause for model miscalibration is related to training set resampling. In\n",
    "general, resampling is encountered when dealing with imbalanced datasets. In this\n",
    "section, we show the effect of resampling on model calibration and the methodology\n",
    "to use when it comes to imbalanced datasets.\n",
    "\n",
    "Let's synthetically generate an imbalanced dataset with 90% of the samples belonging\n",
    "to the majority class and 10% to the minority class."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e6555d75",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make sure to have scikit-learn >= 1.5\n",
    "import sklearn\n",
    "sklearn.__version__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ddcdb44a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import make_classification\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X, y = make_classification(\n",
    "    n_samples=50_000,\n",
    "    n_features=2,\n",
    "    n_redundant=0,\n",
    "    n_clusters_per_class=1,\n",
    "    weights=[0.99, 0.01],\n",
    "    class_sep=2,\n",
    "    random_state=1,\n",
    ")\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, stratify=y, test_size=0.9, random_state=0\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "23f4aad0",
   "metadata": {},
   "source": [
    "\n",
    "As a model, we use a logistic regression model and check the classification report."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f9a2c110",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "logistic_regression = LogisticRegression().fit(X_train, y_train)\n",
    "print(classification_report(y_test, logistic_regression.predict(X_test)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7149c6ca",
   "metadata": {},
   "source": [
    "\n",
    "When it comes to imbalanced datasets, in general, data scientists tend to be\n",
    "unhappy with one of the statistical metrics used. Here, they might be unhappy with\n",
    "the recall metric that is too low for their taste.\n",
    "\n",
    "Let's check what would be the related decision boundary of our model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12b910b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "from sklearn.inspection import DecisionBoundaryDisplay\n",
    "\n",
    "_, ax = plt.subplots()\n",
    "DecisionBoundaryDisplay.from_estimator(\n",
    "    logistic_regression,\n",
    "    X_test,\n",
    "    ax=ax,\n",
    "    cmap=\"coolwarm\",\n",
    "    response_method=\"predict\",\n",
    "    plot_method=\"contour\"\n",
    ")\n",
    "ax.scatter(*X_train.T, c=y_train, cmap=\"coolwarm\", edgecolors=\"black\")\n",
    "_ = ax.set(xlabel=\"Feature 1\", ylabel=\"Feature 2\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "882d223d",
   "metadata": {},
   "source": [
    "\n",
    "So we see that our model is conservative by wrongly classifying sample from the\n",
    "majority class. However, if our data scientists want to improve the recall, they\n",
    "would like to move the decision boundary to classify correctly more samples from the\n",
    "minority class at the cost of misclassifying more samples from the majority class.\n",
    "\n",
    "A body of literature is usually advocating for resampling the training set such that\n",
    "the model is trained on a more balanced dataset. In scikit-learn, the effect of the\n",
    "parameter `class_weight` provide an equivalence to resampling the training set when\n",
    "set to `\"balanced\"`.\n",
    "\n",
    "We therefore repeat the previous experiment but setting this parameter and check the\n",
    "effect on the classification report and the decision boundary."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b87f2209",
   "metadata": {},
   "outputs": [],
   "source": [
    "logistic_regression_balanced = LogisticRegression(class_weight=\"balanced\")\n",
    "logistic_regression_balanced.fit(X_train, y_train)\n",
    "print(classification_report(y_test, logistic_regression_balanced.predict(X_test)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5011fd28",
   "metadata": {},
   "outputs": [],
   "source": [
    "_, ax = plt.subplots()\n",
    "DecisionBoundaryDisplay.from_estimator(\n",
    "    logistic_regression_balanced,\n",
    "    X_test,\n",
    "    ax=ax,\n",
    "    cmap=\"coolwarm\",\n",
    "    response_method=\"predict\",\n",
    "    plot_method=\"contour\",\n",
    ")\n",
    "ax.scatter(*X_train.T, c=y_train, cmap=\"coolwarm\", edgecolors=\"black\")\n",
    "_ = ax.set(xlabel=\"Feature 1\", ylabel=\"Feature 2\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7dd9cd24",
   "metadata": {},
   "source": [
    "\n",
    "So we see that the recall increases at the cost of lowering the precision. This\n",
    "is confirmed by the decision boundary displacement.\n",
    "\n",
    "However, here we completely discard the potential effect on the calibration of the\n",
    "model. Instead to check the hard decision boundary, let's check the decision boundary\n",
    "based on the probability estimates."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a1ddc73d",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axes = plt.subplots(nrows=1, ncols=2, figsize=(12, 5), sharex=True, sharey=True)\n",
    "for ax, model in zip(axes.ravel(), [logistic_regression, logistic_regression_balanced]):\n",
    "    disp = DecisionBoundaryDisplay.from_estimator(\n",
    "        model,\n",
    "        X_test,\n",
    "        ax=ax,\n",
    "        cmap=\"coolwarm\",\n",
    "        response_method=\"predict_proba\",\n",
    "        alpha=0.8,\n",
    "    )\n",
    "    ax.scatter(*X_train.T, c=y_train, cmap=\"coolwarm\", edgecolors=\"black\")\n",
    "    ax.set(xlabel=\"Feature 1\", ylabel=\"Feature 2\")\n",
    "    fig.colorbar(disp.surface_, ax=ax, label=\"Probability estimate\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5e647825",
   "metadata": {},
   "source": [
    "\n",
    "We see that the two models have a very different probability estimates. We should\n",
    "therefore check the calibration of the two models to check if one model is better\n",
    "calibrated than the other."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7139782e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.calibration import CalibrationDisplay\n",
    "\n",
    "disp = CalibrationDisplay.from_estimator(\n",
    "    logistic_regression, X_test, y_test, strategy=\"quantile\", name=\"Unbalanced LR\"\n",
    ")\n",
    "CalibrationDisplay.from_estimator(\n",
    "    logistic_regression_balanced,\n",
    "    X_test,\n",
    "    y_test,\n",
    "    strategy=\"quantile\",\n",
    "    ax=disp.ax_,\n",
    "    name=\"Balanced LR\",\n",
    ")\n",
    "disp.ax_.set(aspect=\"equal\")\n",
    "_ = disp.ax_.legend(loc=\"upper left\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4503ff54",
   "metadata": {},
   "source": [
    "\n",
    "We clearly see that the balanced logistic regression model is completely\n",
    "miscalibrated. In short, this is the effect of resampling. We could have a look at the\n",
    "ROC curves of the two models to check if the predictions ranking changed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f3424825",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import RocCurveDisplay\n",
    "\n",
    "fig, ax = plt.subplots()\n",
    "RocCurveDisplay.from_estimator(\n",
    "    logistic_regression, X_test, y_test, ax=ax, linestyle=\"-.\", name=\"Unbalanced LR\"\n",
    ")\n",
    "RocCurveDisplay.from_estimator(\n",
    "    logistic_regression_balanced,\n",
    "    X_test,\n",
    "    y_test,\n",
    "    ax=ax,\n",
    "    linestyle=\"--\",\n",
    "    name=\"Balanced LR\",\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "83495d52",
   "metadata": {},
   "source": [
    "\n",
    "We see that the two models have the same ROC curve. So it means, that the ranking of\n",
    "the predictions is the same.\n",
    "\n",
    "As a conclusion, we should not use resampling to deal with imbalanced datasets.\n",
    "Instead, if we are interesting in improving a given metric, we should instead\n",
    "tune the threshold that is set to 0.5 by default to transform the probability\n",
    "estimates into hard predictions. It will have the same effect as \"moving\" the\n",
    "decision boundary but it will not impact the calibration of the model. We will go\n",
    "in further details in this topic in the next section. But we can quickly experiment\n",
    "with the `FixedThresholdClassifier` from scikit-learn that allows to set a threshold\n",
    "to transform the probability estimates into hard predictions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "839dcfdb",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import FixedThresholdClassifier\n",
    "\n",
    "threshold = 0.1\n",
    "logistic_regrssion_with_threshold = FixedThresholdClassifier(\n",
    "    logistic_regression, threshold=threshold\n",
    ").fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b87c1ef5",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axes = plt.subplots(nrows=1, ncols=2, figsize=(12, 5), sharex=True, sharey=True)\n",
    "for ax, model, title in zip(\n",
    "    axes.ravel(),\n",
    "    [logistic_regression, logistic_regrssion_with_threshold],\n",
    "    [\"Threshold 0.5 (default)\", f\"Threshold {threshold}\"],\n",
    "):\n",
    "    disp = DecisionBoundaryDisplay.from_estimator(\n",
    "        model,\n",
    "        X_test,\n",
    "        ax=ax,\n",
    "        cmap=\"coolwarm\",\n",
    "        response_method=\"predict\",\n",
    "        plot_method=\"contour\",\n",
    "    )\n",
    "    ax.scatter(*X_train.T, c=y_train, cmap=\"coolwarm\", edgecolors=\"black\")\n",
    "    ax.set(xlabel=\"Feature 1\", ylabel=\"Feature 2\", title=title)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0633583e",
   "metadata": {},
   "source": [
    "\n",
    "We see that the decision boundary similarly to the balanced logistic regression model.\n",
    "In addition, since we have a parameter to tune, we can easily target a certain score\n",
    "for some targeted metric that is not trivial with resampling.\n",
    "\n",
    "We can go further and check that the two models that we have are both calibrated the\n",
    "same way."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b915016",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axes = plt.subplots(nrows=1, ncols=2, figsize=(12, 5), sharex=True, sharey=True)\n",
    "for ax, model, title in zip(\n",
    "    axes.ravel(),\n",
    "    [logistic_regression, logistic_regrssion_with_threshold],\n",
    "    [\"Threshold 0.5 (default)\", f\"Threshold {threshold}\"],\n",
    "):\n",
    "    disp = DecisionBoundaryDisplay.from_estimator(\n",
    "        model,\n",
    "        X_test,\n",
    "        ax=ax,\n",
    "        cmap=\"coolwarm\",\n",
    "        response_method=\"predict_proba\",\n",
    "        alpha=0.8,\n",
    "    )\n",
    "    DecisionBoundaryDisplay.from_estimator(\n",
    "        model,\n",
    "        X_test,\n",
    "        ax=ax,\n",
    "        cmap=\"coolwarm\",\n",
    "        response_method=\"predict\",\n",
    "        plot_method=\"contour\",\n",
    "    )\n",
    "    ax.scatter(*X_train.T, c=y_train, cmap=\"coolwarm\", edgecolors=\"black\")\n",
    "    ax.set(xlabel=\"Feature 1\", ylabel=\"Feature 2\", title=title)\n",
    "    fig.colorbar(disp.surface_, ax=ax, label=\"Probability estimate\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f4365eaf",
   "metadata": {},
   "source": [
    "\n",
    "This is not a surprise since the thresholding is a post-processing that threshold the\n",
    "probability estimates. Therefore, it does not impact the calibration of the model."
   ]
  }
 ],
 "metadata": {
  "jupytext": {
   "cell_metadata_filter": "-all",
   "main_language": "python",
   "notebook_metadata_filter": "-all"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "14db8439",
   "metadata": {},
   "source": [
    "\n",
    "# Classification metrics\n",
    "\n",
    "This notebook illustrates the impact of transforming predicted probabilities\n",
    "on the different metrics used to evaluate classification models.\n",
    "\n",
    "## Ranking metrics are not impacted by monotonic transformations\n",
    "\n",
    "In this exercise, we empirically check that ranking metrics are not impacted\n",
    "by monotonic transformations. We will use the ROC-AUC score as an example.\n",
    "\n",
    "### Exercise:\n",
    "\n",
    "- Write a function that maps values from [0, 1] to [0, 1] in a monotonically\n",
    "  increasing way:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c737834",
   "metadata": {
    "lines_to_next_cell": 2
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "\n",
    "def monotonic_function(x):\n",
    "    # TODO: change me to something non-trivial but still monotonic.\n",
    "    return x\n",
    "\n",
    "\n",
    "x = np.linspace(0, 1, 1000)\n",
    "y = monotonic_function(x)\n",
    "_ = plt.plot(x, y)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ce5173b3",
   "metadata": {},
   "source": [
    "### Solution:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0df52166",
   "metadata": {
    "lines_to_next_cell": 2
   },
   "outputs": [],
   "source": [
    "from scipy.special import expit\n",
    "\n",
    "\n",
    "def monotonic_function(x):\n",
    "    return expit((x - 0.7) * 10) ** 0.4\n",
    "    # Or alternatively, a simple power transformation:\n",
    "    # return x ** 2\n",
    "    # return x ** 0.3\n",
    "\n",
    "\n",
    "x = np.linspace(0, 1, 1000)\n",
    "y = monotonic_function(x)\n",
    "_ = plt.plot(x, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a4eda65",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import roc_auc_score\n",
    "\n",
    "y_observed = np.asarray([1, 0, 1, 1, 0])\n",
    "y_predicted_probs = np.asarray([0.1, 0.9, 0.3, 0.5, 0.2])\n",
    "\n",
    "\n",
    "def compare_metrics(metric_func, transformation_func, y_observed, y_predicted_probs):\n",
    "    metric_name = metric_func.__name__\n",
    "    a = metric_func(y_observed, y_predicted_probs)\n",
    "    b = metric_func(y_observed, transformation_func(y_predicted_probs))\n",
    "\n",
    "    print(f\"{metric_name} on original soft predictions: {a:.4f}\")\n",
    "    print(f\"{metric_name} on transformed soft predictions: {b:.4f}\")\n",
    "\n",
    "\n",
    "compare_metrics(roc_auc_score, monotonic_function, y_observed, y_predicted_probs)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "32d658ab",
   "metadata": {
    "lines_to_next_cell": 2
   },
   "source": [
    "\n",
    "### Exercise:\n",
    "\n",
    "- Check that the same result holds for other ranking metrics such as\n",
    "`average_precision_score`.\n",
    "\n",
    "- Tweak the values in `y_predicted_probs` to see that this\n",
    "property holds in general."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f764473d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import average_precision_score\n",
    "\n",
    "\n",
    "# TODO: tweak me!\n",
    "y_predicted_probs = np.asarray([0.1, 0.9, 0.3, 0.5, 0.2])\n",
    "\n",
    "# TODO: write me!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fa725ed0",
   "metadata": {},
   "source": [
    "### Solution:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e33a8be",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import average_precision_score\n",
    "\n",
    "compare_metrics(\n",
    "    average_precision_score, monotonic_function, y_observed, y_predicted_probs\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f345dd9",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_predicted_probs = np.asarray([0.4, 0.9, 0.3, 0.5, 0.0])\n",
    "compare_metrics(roc_auc_score, monotonic_function, y_observed, y_predicted_probs)\n",
    "compare_metrics(\n",
    "    average_precision_score, monotonic_function, y_observed, y_predicted_probs\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0f741ccb",
   "metadata": {},
   "source": [
    "## Proper scoring rules are impacted by monotonic transformations\n",
    "\n",
    "### Exercise:\n",
    "\n",
    "- Check that `neg_log_loss` and `brier_score_loss` are impacted by monotonic\n",
    "  transformations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f11c9e6",
   "metadata": {
    "lines_to_next_cell": 2
   },
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "# TODO: write me!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "575403f9",
   "metadata": {},
   "source": [
    "### Solution:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b174d12",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import log_loss, brier_score_loss\n",
    "\n",
    "compare_metrics(log_loss, monotonic_function, y_observed, y_predicted_probs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f9d4091d",
   "metadata": {},
   "outputs": [],
   "source": [
    "compare_metrics(brier_score_loss, monotonic_function, y_observed, y_predicted_probs)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b88d9e8f",
   "metadata": {},
   "source": [
    "\n",
    "There is no particular reason to expect that our choice of transformation\n",
    "would improve calibration on this dataset. Ranking is unchanged (as measured\n",
    "by ROC-AUC). As a result, the proper scoring losses are degraded."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e13fe8ea",
   "metadata": {},
   "source": [
    "\n",
    "## Hard classification metrics only depends on the value of the threshold\n",
    "\n",
    "### Question:\n",
    "\n",
    "- Under which conditions are thresholded / hard classification metrics such\n",
    "  as (accuracy, precision, recall, F1 score, ...) impacted by monotonic\n",
    "  transformations of the predicted probabilities?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ea637ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: write me!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1a22928e",
   "metadata": {
    "lines_to_next_cell": 2
   },
   "source": [
    "### Solution:\n",
    "\n",
    "- Thresholded metrics are not impacted by monotonic transformations if the\n",
    "  threshold is left unchanged at 0.5 after the transformation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d8b1331",
   "metadata": {},
   "outputs": [],
   "source": [
    "def threshold_preserving_transformation(x):\n",
    "    return expit((x - 0.5) * 10)\n",
    "\n",
    "\n",
    "x = np.linspace(0, 1, 1000)\n",
    "y = threshold_preserving_transformation(x)\n",
    "plt.plot(x, y)\n",
    "plt.hlines(0.5, 0, 1, colors=\"gray\", linestyles=\"--\")\n",
    "_ = plt.vlines(0.5, 0, 1, colors=\"gray\", linestyles=\"--\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6317e8a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def non_threshold_preserving_transformation(x):\n",
    "    return expit((x - 0.7) * 10)\n",
    "\n",
    "\n",
    "y = non_threshold_preserving_transformation(x)\n",
    "_ = plt.plot(x, y)\n",
    "_ = plt.hlines(0.5, 0, 1, colors=\"gray\", linestyles=\"--\")\n",
    "_ = plt.vlines(0.5, 0, 1, colors=\"gray\", linestyles=\"--\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd711fd8",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import f1_score\n",
    "\n",
    "y_observed = np.asarray([1, 0, 1, 1, 0])\n",
    "y_predicted_probs = np.asarray([0.6, 0.9, 0.3, 0.7, 0.2])\n",
    "\n",
    "f1_score(y_observed, y_predicted_probs >= 0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a0cfa91d",
   "metadata": {},
   "outputs": [],
   "source": [
    "f1_score(y_observed, threshold_preserving_transformation(y_predicted_probs) > 0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d43117c",
   "metadata": {},
   "outputs": [],
   "source": [
    "f1_score(y_observed, non_threshold_preserving_transformation(y_predicted_probs) > 0.5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b2feaa34",
   "metadata": {},
   "source": [
    "\n",
    "### Summary:\n",
    "\n",
    "- Ranking metrics are not impacted by monotonic transformations.\n",
    "- Proper scoring rules are impacted by monotonic transformations: a strictly\n",
    "  increasing transformation change the calibration term of the proper scoring\n",
    "  loss while preserving the grouping loss (ranking) and the irreducible error\n",
    "  (independent of the model predictions).\n",
    "- Threshold can be impacted by monotonic transformation of the soft\n",
    "  predictions if the decision threshold is changed by the transformation.\n",
    "\n",
    "As a consequence:\n",
    "\n",
    "- Using a thresholded metric to evaluate a probabilitic classifier does not\n",
    "  inform us at all about the ability of the model to yield correct soft\n",
    "  predictions. Hard classification metrics are very sensitive to the choice\n",
    "  of the threshold. As a result, they are only meaningful if we also tune the\n",
    "  threshold according to some business objective captured in the choice of\n",
    "  the hard classification metric.\n",
    "- Using a ranking loss to evaluate a probabilistic classifier only partially\n",
    "  informs us about the ability of the model to yield correct soft\n",
    "  predictions.\n",
    "- Proper scoring rules evaluate both calibration and resolution (ranking\n",
    "  power) jointly are the only metrics that are guaranteed to select the best\n",
    "  probabilistic models."
   ]
  }
 ],
 "metadata": {
  "jupytext": {
   "cell_metadata_filter": "-all",
   "main_language": "python",
   "notebook_metadata_filter": "-all"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "529bb9f8",
   "metadata": {},
   "source": [
    "\n",
    "# Choosing a classification metric\n",
    "\n",
    "This notebook illustrates the impact of transforming predicted probabilities\n",
    "on the different metrics used to evaluate classification models. Based on\n",
    "those experiment we derive recommendations of the choice of classification\n",
    "metrics.\n",
    "\n",
    "## Ranking metrics are not impacted by monotonic transformations\n",
    "\n",
    "In this exercise, we empirically check that ranking metrics are not impacted\n",
    "by monotonic transformations. We will use the ROC-AUC score as an example.\n",
    "\n",
    "### Exercise:\n",
    "\n",
    "- Write a function that maps values from [0, 1] to [0, 1] in a monotonically\n",
    "  increasing way:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c97b537",
   "metadata": {
    "lines_to_next_cell": 2
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "\n",
    "def monotonic_function(x):\n",
    "    # TODO: change me to something non-trivial but still monotonic.\n",
    "    return x\n",
    "\n",
    "\n",
    "x = np.linspace(0, 1, 1000)\n",
    "y = monotonic_function(x)\n",
    "_ = plt.plot(x, y)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "507320cc",
   "metadata": {},
   "source": [
    "### Solution:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4906b5ef",
   "metadata": {
    "lines_to_next_cell": 2
   },
   "outputs": [],
   "source": [
    "from scipy.special import expit\n",
    "\n",
    "\n",
    "def monotonic_function(x):\n",
    "    return expit((x - 0.7) * 10) ** 0.4\n",
    "    # Or alternatively, a simple power transformation:\n",
    "    # return x ** 2\n",
    "    # return x ** 0.3\n",
    "\n",
    "\n",
    "x = np.linspace(0, 1, 1000)\n",
    "y = monotonic_function(x)\n",
    "_ = plt.plot(x, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae0b3ae8",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import roc_auc_score\n",
    "\n",
    "y_observed = np.asarray([1, 0, 1, 1, 0])\n",
    "y_predicted_probs = np.asarray([0.1, 0.9, 0.3, 0.5, 0.2])\n",
    "\n",
    "\n",
    "def compare_metrics(metric_func, transformation_func, y_observed, y_predicted_probs):\n",
    "    metric_name = metric_func.__name__\n",
    "    a = metric_func(y_observed, y_predicted_probs)\n",
    "    b = metric_func(y_observed, transformation_func(y_predicted_probs))\n",
    "\n",
    "    print(f\"{metric_name} on original soft predictions: {a:.4f}\")\n",
    "    print(f\"{metric_name} on transformed soft predictions: {b:.4f}\")\n",
    "\n",
    "\n",
    "compare_metrics(roc_auc_score, monotonic_function, y_observed, y_predicted_probs)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "626ee2e9",
   "metadata": {
    "lines_to_next_cell": 2
   },
   "source": [
    "\n",
    "### Exercise:\n",
    "\n",
    "- Check that the same result holds for other ranking metrics such as\n",
    "`average_precision_score`.\n",
    "\n",
    "- Tweak the values in `y_predicted_probs` to see that this\n",
    "property holds in general."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "abee2232",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import average_precision_score\n",
    "\n",
    "\n",
    "# TODO: tweak me!\n",
    "y_predicted_probs = np.asarray([0.1, 0.9, 0.3, 0.5, 0.2])\n",
    "\n",
    "# TODO: write me!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "676ce2fb",
   "metadata": {},
   "source": [
    "### Solution:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a86bff29",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import average_precision_score\n",
    "\n",
    "compare_metrics(\n",
    "    average_precision_score, monotonic_function, y_observed, y_predicted_probs\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d3e7f1ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_predicted_probs = np.asarray([0.4, 0.9, 0.3, 0.5, 0.0])\n",
    "compare_metrics(roc_auc_score, monotonic_function, y_observed, y_predicted_probs)\n",
    "compare_metrics(\n",
    "    average_precision_score, monotonic_function, y_observed, y_predicted_probs\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e494f37a",
   "metadata": {},
   "source": [
    "## Proper scoring rules are impacted by monotonic transformations\n",
    "\n",
    "### Exercise:\n",
    "\n",
    "- Check that `neg_log_loss` and `brier_score_loss` are impacted by monotonic\n",
    "  transformations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "292c45c8",
   "metadata": {
    "lines_to_next_cell": 2
   },
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "# TODO: write me!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8d14d0b8",
   "metadata": {},
   "source": [
    "### Solution:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c5cecf93",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import log_loss, brier_score_loss\n",
    "\n",
    "compare_metrics(log_loss, monotonic_function, y_observed, y_predicted_probs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d0874d77",
   "metadata": {},
   "outputs": [],
   "source": [
    "compare_metrics(brier_score_loss, monotonic_function, y_observed, y_predicted_probs)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6ee1f479",
   "metadata": {},
   "source": [
    "\n",
    "There is no particular reason to expect that our choice of transformation\n",
    "would improve calibration on this dataset. Ranking is unchanged (as measured\n",
    "by ROC-AUC). As a result, the proper scoring losses are degraded."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d0da750a",
   "metadata": {},
   "source": [
    "\n",
    "## Hard classification metrics only depends on the value of the threshold\n",
    "\n",
    "### Question:\n",
    "\n",
    "- Under which conditions are thresholded / hard classification metrics such\n",
    "  as (accuracy, precision, recall, F1 score, ...) impacted by monotonic\n",
    "  transformations of the predicted probabilities?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7309ce3a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: write me!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9ba79453",
   "metadata": {
    "lines_to_next_cell": 2
   },
   "source": [
    "### Solution:\n",
    "\n",
    "- Thresholded metrics are not impacted by monotonic transformations if the\n",
    "  threshold is left unchanged at 0.5 after the transformation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "68d696a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def threshold_preserving_transformation(x):\n",
    "    return expit((x - 0.5) * 10)\n",
    "\n",
    "\n",
    "x = np.linspace(0, 1, 1000)\n",
    "y = threshold_preserving_transformation(x)\n",
    "plt.plot(x, y)\n",
    "plt.hlines(0.5, 0, 1, colors=\"gray\", linestyles=\"--\")\n",
    "_ = plt.vlines(0.5, 0, 1, colors=\"gray\", linestyles=\"--\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "70808fb6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def non_threshold_preserving_transformation(x):\n",
    "    return expit((x - 0.7) * 10)\n",
    "\n",
    "\n",
    "y = non_threshold_preserving_transformation(x)\n",
    "_ = plt.plot(x, y)\n",
    "_ = plt.hlines(0.5, 0, 1, colors=\"gray\", linestyles=\"--\")\n",
    "_ = plt.vlines(0.5, 0, 1, colors=\"gray\", linestyles=\"--\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "89466da6",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import f1_score\n",
    "\n",
    "y_observed = np.asarray([1, 0, 1, 1, 0])\n",
    "y_predicted_probs = np.asarray([0.6, 0.9, 0.3, 0.7, 0.2])\n",
    "\n",
    "f1_score(y_observed, y_predicted_probs >= 0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "296239f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "f1_score(y_observed, threshold_preserving_transformation(y_predicted_probs) > 0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3eebf11e",
   "metadata": {},
   "outputs": [],
   "source": [
    "f1_score(y_observed, non_threshold_preserving_transformation(y_predicted_probs) > 0.5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5a5eac65",
   "metadata": {},
   "source": [
    "\n",
    "### Summary:\n",
    "\n",
    "- Ranking metrics are not impacted by monotonic transformations.\n",
    "- Proper scoring rules are impacted by monotonic transformations: a strictly\n",
    "  increasing transformation changes the calibration term of the proper\n",
    "  scoring loss while preserving the grouping loss (ranking) and the\n",
    "  irreducible error (independent of the model predictions).\n",
    "- Hard classification metrics can be impacted by a monotonic transformation\n",
    "  $t$ of the soft predictions if $t(0.5) \\neq 0.5$ (assuming the default 0.5\n",
    "  decisin threshold).\n",
    "\n",
    "As a consequence:\n",
    "\n",
    "- Using a hard classification metric to evaluate a probabilitic classifier\n",
    "  does not inform us at all about the ability of the model to yield correct\n",
    "  soft predictions. Hard classification metrics can be very sensitive to the\n",
    "  choice of the threshold. As a result, they are only meaningful if we also\n",
    "  tune the threshold according to a specific choice of hard classification\n",
    "  metric that should ideally reflect the business objective.\n",
    "- Using a ranking loss to evaluate a probabilistic classifier only partially\n",
    "  informs us about the ability of the model to yield correct soft\n",
    "  predictions.\n",
    "- Proper scoring rules jointly evaluate both calibration and resolution\n",
    "  (ranking power). They are the only metrics that are guaranteed to identify\n",
    "  the best probabilistic model."
   ]
  }
 ],
 "metadata": {
  "jupytext": {
   "cell_metadata_filter": "-all",
   "main_language": "python",
   "notebook_metadata_filter": "-all"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
